Of course, Kevin! Here's your comprehensive tutorial on correlation and simple linear regression converted into clear, structured, and professional Markdown formatting. All LaTeX math has been preserved using inline code or formula blocks where needed:

---

# Correlation

**Pearson's correlation coefficient** \( r \) is a measure of the strength of the linear relationship between two quantitative variables.

- The coefficient ranges from −1 to 1.
  - \( r = 1 \): Perfect positive linear relationship  
  - \( r = -1 \): Perfect negative linear relationship  
  - \( r = 0 \): No linear relationship  
- Assumes variables are normally distributed.
- If normality is violated (e.g., due to outliers), use **Spearman's rank correlation**.

---

## Formal Test of Correlation

To test the significance of correlation in R:

```r
cor(x, y)            # Calculate Pearson’s correlation coefficient
cor.test(x, y)       # Performs hypothesis test with confidence interval
```

### Example using `immer` and `iris` data:

```r
cor(immer$Y1, immer$Y2)
cor(iris[,1], iris[,3])

cor.test(immer$Y1, immer$Y2)
cor.test(iris[,1], iris[,3])
```

### Hypothesis:

- \( H_0 \): \( \rho = 0 \) (no linear relationship)  
- \( H_a \): \( \rho \ne 0 \) (linear relationship exists)

---

## Lurking Variables and Spurious Correlations

A **spurious correlation** arises from the influence of an unaccounted third variable.

> Example: Correlation between fire damage and number of firefighters doesn’t imply more firefighters cause more damage. The size of the fire (a lurking variable) is the hidden cause influencing both.

Use **partial correlation** to control for such variables when known.

---

## Simpson’s Paradox

**Simpson’s Paradox** describes a scenario where a trend appears in separate groups but reverses when the groups are combined.

---

## Rank Correlation

Use **Spearman’s rank correlation coefficient** when assumptions of normality or linearity are violated.

---

## Partial Correlation

**Partial correlation** measures the relationship between two variables while controlling for the influence of one or more additional variables.

---

# Simple Linear Regression Example (SLR)

We’re modeling cotton yield based on irrigation:

- **Irrigation**: Water in feet per acre (predictor)
- **Yield**: Cotton output in pounds per acre (response)

## Data:

| Observation | Irrigation | Yield | Observation | Irrigation | Yield |
|-------------|------------|-------|-------------|------------|-------|
| 1           | 1.8        | 260   | 8           | 1.5        | 280   |
| 2           | 1.9        | 370   | 9           | 1.5        | 230   |
| 3           | 2.5        | 450   | 10          | 1.2        | 180   |
| 4           | 1.4        | 160   | 11          | 1.3        | 220   |
| 5           | 1.3        | 90    | 12          | 1.8        | 180   |
| 6           | 2.1        | 440   | 13          | 3.5        | 400   |
| 7           | 2.3        | 380   | 14          | 3.5        | 650   |

---

## Descriptive Statistics

| Variable   | Mean     | Std. Deviation | N  |
|------------|----------|----------------|----|
| Yield      | 306.43   | 149.65         | 14 |
| Irrigation | 1.97     | 0.75           | 14 |

---

From here, you would typically compute:

- The **correlation coefficient** between Irrigation and Yield
- The **regression equation**:  
  \[
  \hat{Y} = b_0 + b_1 \cdot X
  \]
- Use **ANOVA output** or **coefficients table** to assess model fit

---

### Lurking variables and Spurious Correlation

#### Spurious Correlations. 

Although you cannot prove causal relations based on correlation coefficients, you can still identify so-called spurious correlations; that is, correlations that are due mostly to the influences of "other" variables. For example, there is a correlation between the total amount of losses in a fire and the number of firemen that were putting out the fire; however, what this correlation does not indicate is that if you call fewer firemen then you would lower the losses. There is a third variable (the initial size of the fire) that influences both the amount of losses and the number of firemen. If you "control" for this variable (e.g., consider only fires of a fixed size), then the correlation will either disappear or perhaps even change its sign. The main problem with spurious correlations is that we typically do not know what the "hidden" agent is. However, in cases when we know where to look, we can use partial correlations that control for (partial out) the influence of specified variables.
